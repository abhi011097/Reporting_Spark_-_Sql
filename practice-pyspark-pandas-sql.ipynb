{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px;color:white;margin:0;font-size:175%;text-align:center;display:fill;border-radius:5px;background-color:#016CC9;overflow:hidden;font-weight:500\">Data Wrangling With Pyspark | Pandas | Sql</div>\n",
    "\n",
    "<h3> Work In Progress</h3>\n",
    "\n",
    "* Data wrangling using Pandas Dataframe and Pyspark Dataframe ( also Spark Sql)\n",
    "* Basic steps in each method (structure check)\n",
    "* Functions to be included \n",
    "    * Grouping \n",
    "    * Aggregations\n",
    "    * Windows functions and Other Analytics Function\n",
    "    * etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b><div style='padding:15px;background-color:#79A7D3;color:white;border-radius:2px;font-size:90%;text-align: center'>1 | Environment Setup</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#DEB078'>1.1 |</span><span style='color:#016CC9'> Install Pyspark</span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "#!pip install pyspark\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#DEB078'>1.2 |</span><span style='color:#016CC9'> Import Required Library </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#DEB078'>1.3 |</span><span style='color:#016CC9'> Configure Spark Session and Properties </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Facts Analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9b7ab01820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "          .master(\"local[*]\") \\\n",
    "          .appName(\"Facts Analysis\") \\\n",
    "          .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "clear_output()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b><div style='padding:15px;background-color:#79A7D3;color:white;border-radius:2px;font-size:90%;text-align: center'>2 | Dataset Setup</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>2.1 |</span><span style='color:#016CC9'> Creating Pandas Dataframe </span></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T11:54:43.753923Z",
     "iopub.status.busy": "2023-01-15T11:54:43.753400Z",
     "iopub.status.idle": "2023-01-15T11:54:43.789215Z",
     "shell.execute_reply": "2023-01-15T11:54:43.788266Z",
     "shell.execute_reply.started": "2023-01-15T11:54:43.753884Z"
    }
   },
   "source": [
    "pandas_df_15=pd.read_csv(\"/kaggle/input/world-happiness/2015.csv\")\n",
    "pandas_df_16=pd.read_csv(\"/kaggle/input/world-happiness/2016.csv\")\n",
    "pandas_df_17=pd.read_csv(\"/kaggle/input/world-happiness/2017.csv\")\n",
    "pandas_df_18=pd.read_csv(\"/kaggle/input/world-happiness/2018.csv\")\n",
    "pandas_df_19=pd.read_csv(\"/kaggle/input/world-happiness/2019.csv\")\n",
    "pandas_df_titanic=pd.read_csv(\"/kaggle/input/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df_15=pd.read_csv(\"/Users/abhi011097/Workspace/Dataset_Analysis/4_World_Happiness_Report/Dataset/2015.csv\")\n",
    "pandas_df_16=pd.read_csv(\"/Users/abhi011097/Workspace/Dataset_Analysis/4_World_Happiness_Report/Dataset/2016.csv\")\n",
    "pandas_df_17=pd.read_csv(\"/Users/abhi011097/Workspace/Dataset_Analysis/4_World_Happiness_Report/Dataset/2017.csv\")\n",
    "pandas_df_18=pd.read_csv(\"/Users/abhi011097/Workspace/Dataset_Analysis/4_World_Happiness_Report/Dataset/2018.csv\")\n",
    "pandas_df_19=pd.read_csv(\"/Users/abhi011097/Workspace/Dataset_Analysis/4_World_Happiness_Report/Dataset/2019.csv\")\n",
    "pandas_df_titanic=pd.read_csv(\"train-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>2.2 |</span><span style='color:#016CC9'> Creating Spark Dataframe </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# From Pandas Dataframe\n",
    "spark_df_15=spark.createDataFrame(pandas_df_15)\n",
    "spark_df_16=spark.createDataFrame(pandas_df_16)\n",
    "spark_df_17=spark.createDataFrame(pandas_df_17)\n",
    "spark_df_18=spark.createDataFrame(pandas_df_18)\n",
    "spark_df_19=spark.createDataFrame(pandas_df_19)\n",
    "\n",
    "# From file directly\n",
    "spark_df_titanic=spark.read\\\n",
    "                      .options(header=\"true\",inferSchema='True')\\\n",
    "                      .csv('train-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>2.3 |</span><span style='color:#016CC9'> Creating Spark Table  </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_15.registerTempTable(\"spark_tbl_15\")\n",
    "spark_df_16.registerTempTable(\"spark_tbl_16\")\n",
    "spark_df_17.registerTempTable(\"spark_tbl_17\")\n",
    "spark_df_18.registerTempTable(\"spark_tbl_18\")\n",
    "spark_df_19.registerTempTable(\"spark_tbl_19\")\n",
    "spark_df_titanic.registerTempTable(\"spark_tbl_titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b><div style='padding:15px;background-color:#79A7D3;color:white;border-radius:2px;font-size:90%;text-align: center'>3 | Investigate Data</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>3.1 |</span><span style='color:#016CC9'> About Partitions of Spark Dataframe  </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_15.rdd.getNumPartitions() # 8 in my local system as it has 8 cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>3.2 |</span><span style='color:#016CC9'> Dataframe Types  </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pandas_df_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>3.3 |</span><span style='color:#016CC9'> Check Schrema  </span></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 12 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Country                        158 non-null    object \n",
      " 1   Region                         158 non-null    object \n",
      " 2   Happiness Rank                 158 non-null    int64  \n",
      " 3   Happiness Score                158 non-null    float64\n",
      " 4   Standard Error                 158 non-null    float64\n",
      " 5   Economy (GDP per Capita)       158 non-null    float64\n",
      " 6   Family                         158 non-null    float64\n",
      " 7   Health (Life Expectancy)       158 non-null    float64\n",
      " 8   Freedom                        158 non-null    float64\n",
      " 9   Trust (Government Corruption)  158 non-null    float64\n",
      " 10  Generosity                     158 non-null    float64\n",
      " 11  Dystopia Residual              158 non-null    float64\n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "pandas_df_15.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Happiness Rank: long (nullable = true)\n",
      " |-- Happiness Score: double (nullable = true)\n",
      " |-- Standard Error: double (nullable = true)\n",
      " |-- Economy (GDP per Capita): double (nullable = true)\n",
      " |-- Family: double (nullable = true)\n",
      " |-- Health (Life Expectancy): double (nullable = true)\n",
      " |-- Freedom: double (nullable = true)\n",
      " |-- Trust (Government Corruption): double (nullable = true)\n",
      " |-- Generosity: double (nullable = true)\n",
      " |-- Dystopia Residual: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_15.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#DEB078'>3.4 |</span><span style='color:#016CC9'> Describe Dataframe  </span></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### For Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------------+-----------------+------------------+--------------------+------------------------+------------------+------------------------+-------------------+-----------------------------+-------------------+------------------+\n",
      "|summary|Country    |Region                   |Happiness Rank   |Happiness Score   |Standard Error      |Economy (GDP per Capita)|Family            |Health (Life Expectancy)|Freedom            |Trust (Government Corruption)|Generosity         |Dystopia Residual |\n",
      "+-------+-----------+-------------------------+-----------------+------------------+--------------------+------------------------+------------------+------------------------+-------------------+-----------------------------+-------------------+------------------+\n",
      "|count  |158        |158                      |158              |158               |158                 |158                     |158               |158                     |158                |158                          |158                |158               |\n",
      "|mean   |null       |null                     |79.49367088607595|5.37573417721519  |0.04788474683544304 |0.8461372151898735      |0.9910459493670887|0.6302593670886075      |0.42861493670886075|0.14342183544303794          |0.23729550632911395|2.098976772151899 |\n",
      "|stddev |null       |null                     |45.75436310480851|1.1450101349520665|0.017146178556969306|0.40312077853791        |0.2723690860079153|0.2470777663021721      |0.15069278393767796|0.12003407357455917          |0.12668493402020536|0.5535497923037984|\n",
      "|min    |Afghanistan|Australia and New Zealand|1                |2.839             |0.01848             |0.0                     |0.0               |0.0                     |0.0                |0.0                          |0.0                |0.32858           |\n",
      "|max    |Zimbabwe   |Western Europe           |158              |7.587             |0.13693             |1.69042                 |1.40223           |1.02525                 |0.66973            |0.55191                      |0.79588            |3.60214           |\n",
      "+-------+-----------+-------------------------+-----------------+------------------+--------------------+------------------------+------------------+------------------------+-------------------+-----------------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_15.describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### For Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79.493671</td>\n",
       "      <td>5.375734</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>0.846137</td>\n",
       "      <td>0.991046</td>\n",
       "      <td>0.630259</td>\n",
       "      <td>0.428615</td>\n",
       "      <td>0.143422</td>\n",
       "      <td>0.237296</td>\n",
       "      <td>2.098977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.754363</td>\n",
       "      <td>1.145010</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.403121</td>\n",
       "      <td>0.272369</td>\n",
       "      <td>0.247078</td>\n",
       "      <td>0.150693</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.126685</td>\n",
       "      <td>0.553550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.839000</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.250000</td>\n",
       "      <td>4.526000</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.545808</td>\n",
       "      <td>0.856823</td>\n",
       "      <td>0.439185</td>\n",
       "      <td>0.328330</td>\n",
       "      <td>0.061675</td>\n",
       "      <td>0.150553</td>\n",
       "      <td>1.759410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79.500000</td>\n",
       "      <td>5.232500</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>0.910245</td>\n",
       "      <td>1.029510</td>\n",
       "      <td>0.696705</td>\n",
       "      <td>0.435515</td>\n",
       "      <td>0.107220</td>\n",
       "      <td>0.216130</td>\n",
       "      <td>2.095415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118.750000</td>\n",
       "      <td>6.243750</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.158448</td>\n",
       "      <td>1.214405</td>\n",
       "      <td>0.811013</td>\n",
       "      <td>0.549092</td>\n",
       "      <td>0.180255</td>\n",
       "      <td>0.309883</td>\n",
       "      <td>2.462415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>7.587000</td>\n",
       "      <td>0.136930</td>\n",
       "      <td>1.690420</td>\n",
       "      <td>1.402230</td>\n",
       "      <td>1.025250</td>\n",
       "      <td>0.669730</td>\n",
       "      <td>0.551910</td>\n",
       "      <td>0.795880</td>\n",
       "      <td>3.602140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Happiness Rank  Happiness Score  Standard Error  \\\n",
       "count      158.000000       158.000000      158.000000   \n",
       "mean        79.493671         5.375734        0.047885   \n",
       "std         45.754363         1.145010        0.017146   \n",
       "min          1.000000         2.839000        0.018480   \n",
       "25%         40.250000         4.526000        0.037268   \n",
       "50%         79.500000         5.232500        0.043940   \n",
       "75%        118.750000         6.243750        0.052300   \n",
       "max        158.000000         7.587000        0.136930   \n",
       "\n",
       "       Economy (GDP per Capita)      Family  Health (Life Expectancy)  \\\n",
       "count                158.000000  158.000000                158.000000   \n",
       "mean                   0.846137    0.991046                  0.630259   \n",
       "std                    0.403121    0.272369                  0.247078   \n",
       "min                    0.000000    0.000000                  0.000000   \n",
       "25%                    0.545808    0.856823                  0.439185   \n",
       "50%                    0.910245    1.029510                  0.696705   \n",
       "75%                    1.158448    1.214405                  0.811013   \n",
       "max                    1.690420    1.402230                  1.025250   \n",
       "\n",
       "          Freedom  Trust (Government Corruption)  Generosity  \\\n",
       "count  158.000000                     158.000000  158.000000   \n",
       "mean     0.428615                       0.143422    0.237296   \n",
       "std      0.150693                       0.120034    0.126685   \n",
       "min      0.000000                       0.000000    0.000000   \n",
       "25%      0.328330                       0.061675    0.150553   \n",
       "50%      0.435515                       0.107220    0.216130   \n",
       "75%      0.549092                       0.180255    0.309883   \n",
       "max      0.669730                       0.551910    0.795880   \n",
       "\n",
       "       Dystopia Residual  \n",
       "count         158.000000  \n",
       "mean            2.098977  \n",
       "std             0.553550  \n",
       "min             0.328580  \n",
       "25%             1.759410  \n",
       "50%             2.095415  \n",
       "75%             2.462415  \n",
       "max             3.602140  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df_15.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>158</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country              Region\n",
       "count           158                 158\n",
       "unique          158                  10\n",
       "top     Switzerland  Sub-Saharan Africa\n",
       "freq              1                  40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df_15.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b><div style='padding:15px;background-color:#79A7D3;color:white;border-radius:2px;font-size:90%;text-align: center'>4 | Basic Introduction with Titanic Data</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>4.1 |</span><span style='color:#016CC9'> Select | Alias | Limit  Data </span></b>  \n",
    " \n",
    "* Select -> To pick or filter columns  (All features or few features)\n",
    "* Alias  ->  Temporary name for columns , table etc.\n",
    "* Limit  ->  Limit can be used to restrict number of rows (Unordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns  and 2 rows only\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|  C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "\n",
      "Selected columns to be viewed along with Alias on column\n",
      "+--------------------+--------------+\n",
      "|                Name|PassengerClass|\n",
      "+--------------------+--------------+\n",
      "|Braund, Mr. Owen ...|             3|\n",
      "|Cumings, Mrs. Joh...|             1|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For all columns use astrick * & limit followed by number for no of rows to be returned if available\n",
    "print (\"All columns  and 2 rows only\")\n",
    "\n",
    "query=\"\"\"Select * \n",
    "             From spark_tbl_titanic  \n",
    "             Limit 2 \"\"\"\n",
    "\n",
    "spark.sql(query).show()\n",
    "\n",
    "\n",
    "# For columns to be viewed provide column name instead of * \n",
    "print(\"Selected columns to be viewed along with Alias on column\")\n",
    "\n",
    "query=\"\"\"Select Name, \n",
    "             Pclass as PassengerClass \n",
    "             From spark_tbl_titanic \n",
    "             Limit 2\"\"\"\n",
    "\n",
    "spark.sql(query).show()  # To select column with space use backticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # For all columns and rows \n",
    "    # pandas_df_titanic\n",
    "    # pandas_df_titanic.iloc[:,:]  --> takes index postitions and column positions   [row,column] \n",
    "    # pandas_df_titanic.loc[:,:]  --> takes index & column name \n",
    "    \n",
    "# All columns and 2 rows \n",
    "    # pandas_df_titanic.iloc[0:2,:] \n",
    "    # pandas_df_titanic.head(2)\n",
    "    # pandas_df_titanic.loc[0:2,:]\n",
    "    \n",
    "pandas_df_titanic.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Survived\n",
       "0   1         0\n",
       "1   2         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Selected column and with alias and 2 rows\n",
    "pandas_df_titanic.loc[0:1,['PassengerId','Survived']].rename(columns={'PassengerId':'Id'})     \n",
    "\n",
    "    # pandas_df_titanic.iloc[0:2,[0,1]].rename(columns={'PassengerId':'Id'})                     --> can also provide slicing \n",
    "    # pandas_df_titanic[['PassengerId','Survived']].rename(columns={'PassengerId':'Id'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|  C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "\n",
      "+---+--------+\n",
      "| Id|Survived|\n",
      "+---+--------+\n",
      "|  1|       0|\n",
      "|  2|       1|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For all Columns and 2 rows\n",
    "spark_df_titanic.select(\"*\")\\\n",
    "                .limit(2)\\\n",
    "                .show()\n",
    "        # spark_df_titanic.limit(2).show()\n",
    "\n",
    "\n",
    "# For Selected column and with alias and 2 rows\n",
    "spark_df_titanic.select(\n",
    "                        F.col(\"PassengerId\").alias('Id'),\n",
    "                        \"Survived\"\n",
    "                        )\\\n",
    "                .limit(2)\\\n",
    "                .show()\n",
    "\n",
    "                # spark_df_titanic.select(\"PassengerId\",\"Survived\").withColumnRenamed(\"PassengerId\",\"Id\").limit(2).show()\n",
    "    \n",
    "# Select  method to select columns list \n",
    "# F.col -> to select column and perform operation on it \n",
    "# alias method to rename temporarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>4.2 | </span><span style='color:#016CC9'> Filter | Order Data </span></b>  \n",
    "* Filter -> condition based restriction on data to be presented\n",
    "* Order -> To present data in some order (ascending,descending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292|       null|       C|\n",
      "|        680|       1|     1|Cardeza, Mr. Thom...|  male|36.0|    0|    1|PC 17755|512.3292|B51 B53 B55|       C|\n",
      "|        738|       1|     1|Lesurer, Mr. Gust...|  male|35.0|    0|    0|PC 17755|512.3292|       B101|       C|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   19950|   263.0|C23 C25 C27|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorted by fare in descending followed by PassengerId in ascending\n",
    "# Where is used to filter and order by to provide order\n",
    "\n",
    "spark.sql(\"\"\"select * \n",
    "             From spark_tbl_titanic \n",
    "             Where Survived=1 \n",
    "             Order by Fare desc, PassengerId asc \n",
    "             Limit 4\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "258          259         1       1                    Ward, Miss. Anna   \n",
       "679          680         1       1  Cardeza, Mr. Thomas Drake Martinez   \n",
       "737          738         1       1              Lesurer, Mr. Gustave J   \n",
       "88            89         1       1          Fortune, Miss. Mabel Helen   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket      Fare        Cabin Embarked  \n",
       "258  female  35.0      0      0  PC 17755  512.3292          NaN        C  \n",
       "679    male  36.0      0      1  PC 17755  512.3292  B51 B53 B55        C  \n",
       "737    male  35.0      0      0  PC 17755  512.3292         B101        C  \n",
       "88   female  23.0      3      2     19950  263.0000  C23 C25 C27        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_mask=(pandas_df_titanic['Survived']==1)\n",
    "\n",
    "pandas_df_titanic.loc[row_mask,:]\\\n",
    "                                 .sort_values(by=['Fare','PassengerId'],ascending=[False,True])\\\n",
    "                                 .head(4)\n",
    "\n",
    "# sort_values is used to order data \n",
    "# row mask containing true and false passed in rows index (true index will be returned) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292|       null|       C|\n",
      "|        680|       1|     1|Cardeza, Mr. Thom...|  male|36.0|    0|    1|PC 17755|512.3292|B51 B53 B55|       C|\n",
      "|        738|       1|     1|Lesurer, Mr. Gust...|  male|35.0|    0|    0|PC 17755|512.3292|       B101|       C|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   19950|   263.0|C23 C25 C27|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_titanic\\\n",
    "                .filter(F.col('Survived')==1)\\\n",
    "                .sort(['Fare','PassengerId'],ascending=[False,True])\\\n",
    "                .limit(4)\\\n",
    "                .show()\n",
    "\n",
    "# filter used to provide condition to filter rows\n",
    "# sort method to order data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>4.3 | </span><span style='color:#016CC9'> Aggregations & Grouping Data </span></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T12:12:00.325414Z",
     "iopub.status.busy": "2023-01-15T12:12:00.319920Z",
     "iopub.status.idle": "2023-01-15T12:12:00.338839Z",
     "shell.execute_reply": "2023-01-15T12:12:00.331458Z",
     "shell.execute_reply.started": "2023-01-15T12:12:00.325301Z"
    }
   },
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|survived|count(1)|\n",
      "+--------+--------+\n",
      "|       1|     342|\n",
      "|       0|     549|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select survived , count(1) from spark_tbl_titanic group by 1 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------+------------------+\n",
      "|survived|Age_Min|Age_Max|        Total_Fare|\n",
      "+--------+-------+-------+------------------+\n",
      "|       1|   0.42|   80.0|16551.229399999997|\n",
      "|       0|    1.0|   74.0|12142.719899999987|\n",
      "+--------+-------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select survived , min(Age) Age_Min , max(Age) Age_Max ,sum(Fare) Total_Fare from spark_tbl_titanic group by 1 \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_titanic\\\n",
    "        .groupBy('survived')\\\n",
    "        .count()\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------+------------------+\n",
      "|survived|Age_Min|Age_Max|        Total_Fare|\n",
      "+--------+-------+-------+------------------+\n",
      "|       1|   0.42|   80.0|16551.229399999997|\n",
      "|       0|    1.0|   74.0|12142.719899999987|\n",
      "+--------+-------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_titanic\\\n",
    "    .groupBy('survived')\\\n",
    "    .agg(F.min(\"Age\").alias(\"Age_Min\") , \n",
    "         F.max(\"Age\").alias(\"Age_Max\") ,\n",
    "         F.sum(\"Fare\").alias(\"Total_Fare\") ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas_df_titanic['Survived'].value_counts() \n",
    "# pandas_df_titanic.groupby('Survived')['Survived'].count()\n",
    "pandas_df_titanic.groupby('Survived').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_min</th>\n",
       "      <th>age_max</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12142.7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16551.2294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age_min  age_max        Fare\n",
       "Survived                              \n",
       "0            1.00     74.0  12142.7199\n",
       "1            0.42     80.0  16551.2294"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregation\n",
    "\n",
    "pandas_df_titanic.groupby(\"Survived\").agg(\n",
    "     age_min=pd.NamedAgg(column=\"Age\", aggfunc=\"min\"),\n",
    "     age_max=pd.NamedAgg(column=\"Age\", aggfunc=\"max\"),\n",
    "     Fare=pd.NamedAgg(column=\"Fare\", aggfunc=\"sum\"),\n",
    "\n",
    ")\n",
    "\n",
    "#pandas_df_titanic.groupby('Survived').agg({'Age': ['min', 'max'], 'Fare': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Multiple Datasources (Joins)  --Inprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b><div style='padding:15px;background-color:#79A7D3;color:white;border-radius:2px;font-size:90%;text-align: center'>5 | Complex Query Using World Happiness Data</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>5.1 | </span><span style='color:#016CC9'> Understand features available for reporting in all files </span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_df_15 ->  ['Country', 'Region', 'Happiness Rank', 'Happiness Score', 'Standard Error', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual']\n",
      "pandas_df_16 ->  ['Country', 'Region', 'Happiness Rank', 'Happiness Score', 'Lower Confidence Interval', 'Upper Confidence Interval', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual']\n",
      "pandas_df_17 ->  ['Country', 'Happiness.Rank', 'Happiness.Score', 'Whisker.high', 'Whisker.low', 'Economy..GDP.per.Capita.', 'Family', 'Health..Life.Expectancy.', 'Freedom', 'Generosity', 'Trust..Government.Corruption.', 'Dystopia.Residual']\n",
      "pandas_df_18 ->  ['Overall rank', 'Country or region', 'Score', 'GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n",
      "pandas_df_19 ->  ['Overall rank', 'Country or region', 'Score', 'GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n"
     ]
    }
   ],
   "source": [
    "print(\"pandas_df_15 -> \",pandas_df_15.columns.to_list())\n",
    "print(\"pandas_df_16 -> \",pandas_df_16.columns.to_list())\n",
    "print(\"pandas_df_17 -> \",pandas_df_17.columns.to_list())\n",
    "print(\"pandas_df_18 -> \",pandas_df_18.columns.to_list())\n",
    "print(\"pandas_df_19 -> \",pandas_df_19.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>5.2 | </span><span style='color:#016CC9'> In 2019 Performance of top 5 Happiest countries in each of category </span></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------------------+-------------------+-----------+------------+---------------+---------------------------+\n",
      "|Overall_rank|    Country|GDP_per_capita_Rank|Social_Support_Rank|Health_Rank|Freedom_Rank|Generosity_Rank|Perceptions_corruption_Rank|\n",
      "+------------+-----------+-------------------+-------------------+-----------+------------+---------------+---------------------------+\n",
      "|           1|    Finland|                 23|                  2|         28|           5|             92|                          4|\n",
      "|           2|    Denmark|                 14|                  4|         25|           6|             37|                          3|\n",
      "|           3|     Norway|                  7|                  3|         14|           3|             22|                          8|\n",
      "|           4|    Iceland|                 15|                  1|         15|           7|              8|                         49|\n",
      "|           5|Netherlands|                 12|                 15|         20|          17|             13|                         12|\n",
      "+------------+-----------+-------------------+-------------------+-----------+------------+---------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Overall rank` Overall_rank,`Country or region` Country,\n",
    "          rank() over (order by `GDP per capita` desc) as GDP_per_capita_Rank,\n",
    "          rank() over (order by `Social support` desc) as Social_Support_Rank,\n",
    "          rank() over (order by `Healthy life expectancy` desc) as Health_Rank,\n",
    "          rank() over (order by `Freedom to make life choices` desc) as Freedom_Rank,\n",
    "          rank() over (order by `Generosity` desc) as Generosity_Rank,\n",
    "          rank() over (order by `Perceptions of corruption` desc) as Perceptions_corruption_Rank\n",
    "          from spark_tbl_19\n",
    "          order by `Overall rank` \n",
    "          limit 10\n",
    "          \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall rank</th>\n",
       "      <th>Country or region</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Finland</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Norway</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Overall rank Country or region  GDP per capita  Social support  \\\n",
       "0             1           Finland              23               2   \n",
       "1             2           Denmark              14               4   \n",
       "2             3            Norway               7               3   \n",
       "3             4           Iceland              15               1   \n",
       "4             5       Netherlands              12              15   \n",
       "\n",
       "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
       "0                       28                             5          92   \n",
       "1                       25                             6          37   \n",
       "2                       14                             3          22   \n",
       "3                       15                             7           8   \n",
       "4                       20                            17          13   \n",
       "\n",
       "   Perceptions of corruption  \n",
       "0                          4  \n",
       "1                          3  \n",
       "2                          8  \n",
       "3                         49  \n",
       "4                         12  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pandas_df_19[['Overall rank','Country or region']],pandas_df_19.rank(\n",
    "    axis = 0,\n",
    "    method = 'min',\n",
    "    numeric_only = True,\n",
    "    na_option = 'keep',\n",
    "    ascending = False,\n",
    "    pct = False\n",
    ").astype(np.int16).iloc[:,2:]],axis=1).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------+--------------+-----------------------+----------------------------+----------+-------------------------+\n",
      "|Overall rank|Country or region|GDP per capita|Social support|Healthy life expectancy|Freedom to make life choices|Generosity|Perceptions of corruption|\n",
      "+------------+-----------------+--------------+--------------+-----------------------+----------------------------+----------+-------------------------+\n",
      "|           1|          Finland|            23|             2|                     28|                           5|        92|                        4|\n",
      "|           2|          Denmark|            14|             4|                     25|                           6|        37|                        3|\n",
      "|           3|           Norway|             7|             3|                     14|                           3|        22|                        8|\n",
      "|           4|          Iceland|            15|             1|                     15|                           7|         8|                       49|\n",
      "|           5|      Netherlands|            12|            15|                     20|                          17|        13|                       12|\n",
      "+------------+-----------------+--------------+--------------+-----------------------+----------------------------+----------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark_df_19\\\n",
    "    .drop('Score')\\\n",
    "    .withColumn(\"GDP per capita\",F.rank().over(Window.orderBy(F.col('`GDP per capita`').desc()))) \\\n",
    "    .withColumn(\"Social support\",F.rank().over(Window.orderBy(F.col(\"Social support\").desc()))) \\\n",
    "    .withColumn(\"Healthy life expectancy\",F.rank().over(Window.orderBy(F.col(\"Healthy life expectancy\").desc()))) \\\n",
    "    .withColumn(\"Freedom to make life choices\",F.rank().over(Window.orderBy(F.col(\"Freedom to make life choices\").desc()))) \\\n",
    "    .withColumn(\"Generosity\",F.rank().over(Window.orderBy(F.col(\"Generosity\").desc()))) \\\n",
    "    .withColumn(\"Perceptions of corruption\",F.rank().over(Window.orderBy(F.col(\"Perceptions of corruption\").desc()))) \\\n",
    "    .sort('Overall rank')\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>5.3 | </span><span style='color:#016CC9'> Find the top 3 Countries in each year  </span></b>  \n",
    "* sorted in yearwise followed by rank\n",
    "\n",
    "* Output Format Using Pivot\n",
    "\n",
    "    *  2015  | rank1 | rank2 | rank3 | rank4 | rank5\n",
    "    *  2016  | rank1 | rank2 | rank3 | rank4 | rank5\n",
    "    * ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "|year|     Rank_1|     Rank_2| Rank_3|     Rank_4|     Rank_5|\n",
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "|2015|Switzerland|    Iceland|Denmark|     Norway|     Canada|\n",
      "|2016|    Denmark|Switzerland|Iceland|     Norway|    Finland|\n",
      "|2017|     Norway|    Denmark|Iceland|Switzerland|    Finland|\n",
      "|2018|    Finland|     Norway|Denmark|    Iceland|Switzerland|\n",
      "|2019|    Finland|    Denmark| Norway|    Iceland|Netherlands|\n",
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            with ref_tbl as \n",
    "                    (Select year,rank,country from (\n",
    "                        select country,`Happiness Rank` as rank , '2015' year  from spark_tbl_15 where `Happiness Rank`  <= 5\n",
    "                        union\n",
    "                        select country,`Happiness Rank` as rank , '2016' year  from spark_tbl_16 where `Happiness Rank`  <= 5\n",
    "                        union\n",
    "                        select country,`Happiness.Rank` as rank , '2017' year  from spark_tbl_17 where `Happiness.Rank`  <= 5\n",
    "                        union\n",
    "                        select `Country or region` country,`Overall rank` as rank , '2018' year  from spark_tbl_18 where `Overall rank`  <= 5\n",
    "                        union\n",
    "                        select `Country or region` country,`Overall rank` as rank , '2019' year  from spark_tbl_19 where `Overall rank`  <= 5       \n",
    "                      ) order by 1 asc,2 asc)\n",
    "                      \n",
    "            select * from ref_tbl\n",
    "            PIVOT (\n",
    "                      max(country)\n",
    "                      FOR rank in (\n",
    "                        1 Rank_1, 2 Rank_2, 3 Rank_3, 4 Rank_4, 5 Rank_5\n",
    "                      )\n",
    "                    )\n",
    "            ORDER BY year\n",
    "                      \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank_1</th>\n",
       "      <th>Rank_2</th>\n",
       "      <th>Rank_3</th>\n",
       "      <th>Rank_4</th>\n",
       "      <th>Rank_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rank_1       Rank_2   Rank_3       Rank_4       Rank_5\n",
       "Year                                                             \n",
       "2015  Switzerland      Iceland  Denmark       Norway       Canada\n",
       "2016      Denmark  Switzerland  Iceland       Norway      Finland\n",
       "2017       Norway      Denmark  Iceland  Switzerland      Finland\n",
       "2018      Finland       Norway  Denmark      Iceland  Switzerland\n",
       "2019      Finland      Denmark   Norway      Iceland  Netherlands"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_res=pd.concat([\n",
    "    pandas_df_15[['Country','Happiness Rank']].assign(Year='2015').rename(columns={'Happiness Rank':'Rank'}), \n",
    "    pandas_df_16[['Country','Happiness Rank']].assign(Year='2016').rename(columns={'Happiness Rank':'Rank'}),\n",
    "    pandas_df_17[['Country','Happiness.Rank']].assign(Year='2017').rename(columns={'Happiness.Rank':'Rank'}),\n",
    "    pandas_df_18[['Country or region','Overall rank']].assign(Year='2018').rename(columns={'Country or region':'Country','Overall rank':'Rank'}),\n",
    "    pandas_df_19[['Country or region','Overall rank']].assign(Year='2019').rename(columns={'Country or region':'Country','Overall rank':'Rank'})\n",
    "        ])\n",
    "\n",
    "temp_res[temp_res['Rank']<=5]\\\n",
    "    .pivot(index='Year', columns='Rank', values='Country')\\\n",
    "    .rename(columns={1:'Rank_1',2:'Rank_2',3:'Rank_3',4:'Rank_4',5:'Rank_5'})\\\n",
    "    .rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>    (37 + 3) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "|Year|     Rank_1|     Rank_2| Rank_3|     Rank_4|     Rank_5|\n",
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "|2015|Switzerland|    Iceland|Denmark|     Norway|     Canada|\n",
      "|2016|    Denmark|Switzerland|Iceland|     Norway|    Finland|\n",
      "|2017|     Norway|    Denmark|Iceland|Switzerland|    Finland|\n",
      "|2018|    Finland|     Norway|Denmark|    Iceland|Switzerland|\n",
      "|2019|    Finland|    Denmark| Norway|    Iceland|Netherlands|\n",
      "+----+-----------+-----------+-------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df_15['Country','Happiness Rank'].withColumnRenamed(\"Happiness Rank\",\"Rank\").withColumn('Year',F.lit(2015))\\\n",
    "    .union(spark_df_16['Country','Happiness Rank'].withColumnRenamed(\"Happiness Rank\",\"Rank\").withColumn('Year',F.lit(2016)))\\\n",
    "    .union(spark_df_17.select('Country',F.col('`Happiness.Rank`').alias('Rank'),F.lit(2017).alias('Year')))\\\n",
    "    .union(spark_df_18.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank'),F.lit(2018).alias('Year')))\\\n",
    "    .union(spark_df_19.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank'),F.lit(2019).alias('Year')))\\\n",
    "    .filter(F.col('Rank') <=5)\\\n",
    "    .groupBy(\"Year\").pivot(\"Rank\").agg(F.first('Country'))\\\n",
    "    .withColumnRenamed(\"1\",\"Rank_1\").withColumnRenamed(\"2\",\"Rank_2\").withColumnRenamed(\"3\",\"Rank_3\")\\\n",
    "    .withColumnRenamed(\"4\",\"Rank_4\").withColumnRenamed(\"5\",\"Rank_5\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>5.4 | </span><span style='color:#016CC9'> Find the countries which never observed a drop in rank along with year wise rank and diffence of rank from 2015 to 2019 </span></b>   \n",
    "* Sort the data by biggest to lowest change between 2015 to 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "|            Country|Rank_2015|Rank_2016|Rank_2017|Rank_2018|Rank_2019|Increment_Factor|\n",
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "|              Benin|      155|      153|      143|      136|      102|              53|\n",
      "|        Ivory Coast|      151|      139|      128|      107|       99|              52|\n",
      "|           Honduras|      105|      104|       91|       72|       59|              46|\n",
      "|            Hungary|      104|       91|       75|       69|       62|              42|\n",
      "|            Romania|       86|       71|       57|       52|       48|              38|\n",
      "|       Burkina Faso|      152|      145|      134|      121|      115|              37|\n",
      "|           Cameroon|      133|      114|      107|       99|       96|              37|\n",
      "|           Bulgaria|      134|      129|      105|      100|       97|              37|\n",
      "|Congo (Brazzaville)|      139|      127|      124|      114|      103|              36|\n",
      "|           Cambodia|      145|      140|      129|      120|      109|              36|\n",
      "|             Latvia|       89|       68|       54|       53|       53|              36|\n",
      "|         Tajikistan|      106|      100|       96|       88|       74|              32|\n",
      "|              Niger|      144|      142|      135|      134|      114|              30|\n",
      "| Dominican Republic|       98|       89|       86|       83|       77|              21|\n",
      "|        Philippines|       90|       82|       72|       71|       69|              21|\n",
      "|             Poland|       60|       57|       46|       42|       40|              20|\n",
      "|               Togo|      158|      155|      150|      139|      139|              19|\n",
      "|            Estonia|       73|       72|       66|       63|       55|              18|\n",
      "|              Malta|       37|       30|       27|       22|       22|              15|\n",
      "|              Italy|       50|       50|       48|       47|       36|              14|\n",
      "|     Czech Republic|       31|       27|       23|       21|       20|              11|\n",
      "|              Syria|      156|      156|      152|      150|      149|               7|\n",
      "|           Slovakia|       45|       45|       40|       39|       38|               7|\n",
      "|            Finland|        6|        5|        5|        1|        1|               5|\n",
      "|        Netherlands|        7|        7|        6|        6|        5|               2|\n",
      "|        New Zealand|        9|        8|        8|        8|        8|               1|\n",
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"Select t1.Country ,t1.`Happiness Rank` as Rank_2015,t2.`Happiness Rank` Rank_2016,t3.`Happiness.Rank`  Rank_2017, \n",
    "            t4.`Overall rank` Rank_2018 ,t5.`Overall rank` Rank_2019,\n",
    "            (t1.`Happiness Rank`-t5.`Overall rank`) Increment_Factor\n",
    "            from  spark_tbl_15  t1\n",
    "            inner join spark_tbl_16 t2\n",
    "            on t1.Country = t2.Country and t1.`Happiness Rank` >= t2.`Happiness Rank`\n",
    "            inner join spark_tbl_17 t3\n",
    "            on t1.Country = t3.Country and t2.`Happiness Rank` >= t3.`Happiness.Rank`\n",
    "            inner join spark_tbl_18 t4\n",
    "            on t1.Country = t4.`Country or region` and t3.`Happiness.Rank` >= t4.`Overall rank`\n",
    "            inner join spark_tbl_19 t5\n",
    "            on t1.Country = t5.`Country or region` and t4.`Overall rank` >= t5.`Overall rank`\n",
    "            order by Increment_Factor desc\n",
    "          \n",
    "          \"\"\").show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9c404\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_9c404_level0_col0\" class=\"col_heading level0 col0\" >Country</th>\n",
       "      <th id=\"T_9c404_level0_col1\" class=\"col_heading level0 col1\" >Rank_2015</th>\n",
       "      <th id=\"T_9c404_level0_col2\" class=\"col_heading level0 col2\" >Rank_2016</th>\n",
       "      <th id=\"T_9c404_level0_col3\" class=\"col_heading level0 col3\" >Rank_2017</th>\n",
       "      <th id=\"T_9c404_level0_col4\" class=\"col_heading level0 col4\" >Rank_2018</th>\n",
       "      <th id=\"T_9c404_level0_col5\" class=\"col_heading level0 col5\" >Rank_2019</th>\n",
       "      <th id=\"T_9c404_level0_col6\" class=\"col_heading level0 col6\" >Increment_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row0_col0\" class=\"data row0 col0\" >Benin</td>\n",
       "      <td id=\"T_9c404_row0_col1\" class=\"data row0 col1\" >155</td>\n",
       "      <td id=\"T_9c404_row0_col2\" class=\"data row0 col2\" >153</td>\n",
       "      <td id=\"T_9c404_row0_col3\" class=\"data row0 col3\" >143</td>\n",
       "      <td id=\"T_9c404_row0_col4\" class=\"data row0 col4\" >136</td>\n",
       "      <td id=\"T_9c404_row0_col5\" class=\"data row0 col5\" >102</td>\n",
       "      <td id=\"T_9c404_row0_col6\" class=\"data row0 col6\" >53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row1_col0\" class=\"data row1 col0\" >Ivory Coast</td>\n",
       "      <td id=\"T_9c404_row1_col1\" class=\"data row1 col1\" >151</td>\n",
       "      <td id=\"T_9c404_row1_col2\" class=\"data row1 col2\" >139</td>\n",
       "      <td id=\"T_9c404_row1_col3\" class=\"data row1 col3\" >128</td>\n",
       "      <td id=\"T_9c404_row1_col4\" class=\"data row1 col4\" >107</td>\n",
       "      <td id=\"T_9c404_row1_col5\" class=\"data row1 col5\" >99</td>\n",
       "      <td id=\"T_9c404_row1_col6\" class=\"data row1 col6\" >52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row2_col0\" class=\"data row2 col0\" >Honduras</td>\n",
       "      <td id=\"T_9c404_row2_col1\" class=\"data row2 col1\" >105</td>\n",
       "      <td id=\"T_9c404_row2_col2\" class=\"data row2 col2\" >104</td>\n",
       "      <td id=\"T_9c404_row2_col3\" class=\"data row2 col3\" >91</td>\n",
       "      <td id=\"T_9c404_row2_col4\" class=\"data row2 col4\" >72</td>\n",
       "      <td id=\"T_9c404_row2_col5\" class=\"data row2 col5\" >59</td>\n",
       "      <td id=\"T_9c404_row2_col6\" class=\"data row2 col6\" >46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row3_col0\" class=\"data row3 col0\" >Hungary</td>\n",
       "      <td id=\"T_9c404_row3_col1\" class=\"data row3 col1\" >104</td>\n",
       "      <td id=\"T_9c404_row3_col2\" class=\"data row3 col2\" >91</td>\n",
       "      <td id=\"T_9c404_row3_col3\" class=\"data row3 col3\" >75</td>\n",
       "      <td id=\"T_9c404_row3_col4\" class=\"data row3 col4\" >69</td>\n",
       "      <td id=\"T_9c404_row3_col5\" class=\"data row3 col5\" >62</td>\n",
       "      <td id=\"T_9c404_row3_col6\" class=\"data row3 col6\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row4_col0\" class=\"data row4 col0\" >Romania</td>\n",
       "      <td id=\"T_9c404_row4_col1\" class=\"data row4 col1\" >86</td>\n",
       "      <td id=\"T_9c404_row4_col2\" class=\"data row4 col2\" >71</td>\n",
       "      <td id=\"T_9c404_row4_col3\" class=\"data row4 col3\" >57</td>\n",
       "      <td id=\"T_9c404_row4_col4\" class=\"data row4 col4\" >52</td>\n",
       "      <td id=\"T_9c404_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_9c404_row4_col6\" class=\"data row4 col6\" >38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row5_col0\" class=\"data row5 col0\" >Cameroon</td>\n",
       "      <td id=\"T_9c404_row5_col1\" class=\"data row5 col1\" >133</td>\n",
       "      <td id=\"T_9c404_row5_col2\" class=\"data row5 col2\" >114</td>\n",
       "      <td id=\"T_9c404_row5_col3\" class=\"data row5 col3\" >107</td>\n",
       "      <td id=\"T_9c404_row5_col4\" class=\"data row5 col4\" >99</td>\n",
       "      <td id=\"T_9c404_row5_col5\" class=\"data row5 col5\" >96</td>\n",
       "      <td id=\"T_9c404_row5_col6\" class=\"data row5 col6\" >37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row6_col0\" class=\"data row6 col0\" >Burkina Faso</td>\n",
       "      <td id=\"T_9c404_row6_col1\" class=\"data row6 col1\" >152</td>\n",
       "      <td id=\"T_9c404_row6_col2\" class=\"data row6 col2\" >145</td>\n",
       "      <td id=\"T_9c404_row6_col3\" class=\"data row6 col3\" >134</td>\n",
       "      <td id=\"T_9c404_row6_col4\" class=\"data row6 col4\" >121</td>\n",
       "      <td id=\"T_9c404_row6_col5\" class=\"data row6 col5\" >115</td>\n",
       "      <td id=\"T_9c404_row6_col6\" class=\"data row6 col6\" >37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row7_col0\" class=\"data row7 col0\" >Bulgaria</td>\n",
       "      <td id=\"T_9c404_row7_col1\" class=\"data row7 col1\" >134</td>\n",
       "      <td id=\"T_9c404_row7_col2\" class=\"data row7 col2\" >129</td>\n",
       "      <td id=\"T_9c404_row7_col3\" class=\"data row7 col3\" >105</td>\n",
       "      <td id=\"T_9c404_row7_col4\" class=\"data row7 col4\" >100</td>\n",
       "      <td id=\"T_9c404_row7_col5\" class=\"data row7 col5\" >97</td>\n",
       "      <td id=\"T_9c404_row7_col6\" class=\"data row7 col6\" >37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row8_col0\" class=\"data row8 col0\" >Cambodia</td>\n",
       "      <td id=\"T_9c404_row8_col1\" class=\"data row8 col1\" >145</td>\n",
       "      <td id=\"T_9c404_row8_col2\" class=\"data row8 col2\" >140</td>\n",
       "      <td id=\"T_9c404_row8_col3\" class=\"data row8 col3\" >129</td>\n",
       "      <td id=\"T_9c404_row8_col4\" class=\"data row8 col4\" >120</td>\n",
       "      <td id=\"T_9c404_row8_col5\" class=\"data row8 col5\" >109</td>\n",
       "      <td id=\"T_9c404_row8_col6\" class=\"data row8 col6\" >36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row9_col0\" class=\"data row9 col0\" >Congo (Brazzaville)</td>\n",
       "      <td id=\"T_9c404_row9_col1\" class=\"data row9 col1\" >139</td>\n",
       "      <td id=\"T_9c404_row9_col2\" class=\"data row9 col2\" >127</td>\n",
       "      <td id=\"T_9c404_row9_col3\" class=\"data row9 col3\" >124</td>\n",
       "      <td id=\"T_9c404_row9_col4\" class=\"data row9 col4\" >114</td>\n",
       "      <td id=\"T_9c404_row9_col5\" class=\"data row9 col5\" >103</td>\n",
       "      <td id=\"T_9c404_row9_col6\" class=\"data row9 col6\" >36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row10_col0\" class=\"data row10 col0\" >Latvia</td>\n",
       "      <td id=\"T_9c404_row10_col1\" class=\"data row10 col1\" >89</td>\n",
       "      <td id=\"T_9c404_row10_col2\" class=\"data row10 col2\" >68</td>\n",
       "      <td id=\"T_9c404_row10_col3\" class=\"data row10 col3\" >54</td>\n",
       "      <td id=\"T_9c404_row10_col4\" class=\"data row10 col4\" >53</td>\n",
       "      <td id=\"T_9c404_row10_col5\" class=\"data row10 col5\" >53</td>\n",
       "      <td id=\"T_9c404_row10_col6\" class=\"data row10 col6\" >36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row11_col0\" class=\"data row11 col0\" >Tajikistan</td>\n",
       "      <td id=\"T_9c404_row11_col1\" class=\"data row11 col1\" >106</td>\n",
       "      <td id=\"T_9c404_row11_col2\" class=\"data row11 col2\" >100</td>\n",
       "      <td id=\"T_9c404_row11_col3\" class=\"data row11 col3\" >96</td>\n",
       "      <td id=\"T_9c404_row11_col4\" class=\"data row11 col4\" >88</td>\n",
       "      <td id=\"T_9c404_row11_col5\" class=\"data row11 col5\" >74</td>\n",
       "      <td id=\"T_9c404_row11_col6\" class=\"data row11 col6\" >32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row12_col0\" class=\"data row12 col0\" >Niger</td>\n",
       "      <td id=\"T_9c404_row12_col1\" class=\"data row12 col1\" >144</td>\n",
       "      <td id=\"T_9c404_row12_col2\" class=\"data row12 col2\" >142</td>\n",
       "      <td id=\"T_9c404_row12_col3\" class=\"data row12 col3\" >135</td>\n",
       "      <td id=\"T_9c404_row12_col4\" class=\"data row12 col4\" >134</td>\n",
       "      <td id=\"T_9c404_row12_col5\" class=\"data row12 col5\" >114</td>\n",
       "      <td id=\"T_9c404_row12_col6\" class=\"data row12 col6\" >30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row13_col0\" class=\"data row13 col0\" >Philippines</td>\n",
       "      <td id=\"T_9c404_row13_col1\" class=\"data row13 col1\" >90</td>\n",
       "      <td id=\"T_9c404_row13_col2\" class=\"data row13 col2\" >82</td>\n",
       "      <td id=\"T_9c404_row13_col3\" class=\"data row13 col3\" >72</td>\n",
       "      <td id=\"T_9c404_row13_col4\" class=\"data row13 col4\" >71</td>\n",
       "      <td id=\"T_9c404_row13_col5\" class=\"data row13 col5\" >69</td>\n",
       "      <td id=\"T_9c404_row13_col6\" class=\"data row13 col6\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row14_col0\" class=\"data row14 col0\" >Dominican Republic</td>\n",
       "      <td id=\"T_9c404_row14_col1\" class=\"data row14 col1\" >98</td>\n",
       "      <td id=\"T_9c404_row14_col2\" class=\"data row14 col2\" >89</td>\n",
       "      <td id=\"T_9c404_row14_col3\" class=\"data row14 col3\" >86</td>\n",
       "      <td id=\"T_9c404_row14_col4\" class=\"data row14 col4\" >83</td>\n",
       "      <td id=\"T_9c404_row14_col5\" class=\"data row14 col5\" >77</td>\n",
       "      <td id=\"T_9c404_row14_col6\" class=\"data row14 col6\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row15_col0\" class=\"data row15 col0\" >Poland</td>\n",
       "      <td id=\"T_9c404_row15_col1\" class=\"data row15 col1\" >60</td>\n",
       "      <td id=\"T_9c404_row15_col2\" class=\"data row15 col2\" >57</td>\n",
       "      <td id=\"T_9c404_row15_col3\" class=\"data row15 col3\" >46</td>\n",
       "      <td id=\"T_9c404_row15_col4\" class=\"data row15 col4\" >42</td>\n",
       "      <td id=\"T_9c404_row15_col5\" class=\"data row15 col5\" >40</td>\n",
       "      <td id=\"T_9c404_row15_col6\" class=\"data row15 col6\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row16_col0\" class=\"data row16 col0\" >Togo</td>\n",
       "      <td id=\"T_9c404_row16_col1\" class=\"data row16 col1\" >158</td>\n",
       "      <td id=\"T_9c404_row16_col2\" class=\"data row16 col2\" >155</td>\n",
       "      <td id=\"T_9c404_row16_col3\" class=\"data row16 col3\" >150</td>\n",
       "      <td id=\"T_9c404_row16_col4\" class=\"data row16 col4\" >139</td>\n",
       "      <td id=\"T_9c404_row16_col5\" class=\"data row16 col5\" >139</td>\n",
       "      <td id=\"T_9c404_row16_col6\" class=\"data row16 col6\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row17_col0\" class=\"data row17 col0\" >Estonia</td>\n",
       "      <td id=\"T_9c404_row17_col1\" class=\"data row17 col1\" >73</td>\n",
       "      <td id=\"T_9c404_row17_col2\" class=\"data row17 col2\" >72</td>\n",
       "      <td id=\"T_9c404_row17_col3\" class=\"data row17 col3\" >66</td>\n",
       "      <td id=\"T_9c404_row17_col4\" class=\"data row17 col4\" >63</td>\n",
       "      <td id=\"T_9c404_row17_col5\" class=\"data row17 col5\" >55</td>\n",
       "      <td id=\"T_9c404_row17_col6\" class=\"data row17 col6\" >18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row18_col0\" class=\"data row18 col0\" >Malta</td>\n",
       "      <td id=\"T_9c404_row18_col1\" class=\"data row18 col1\" >37</td>\n",
       "      <td id=\"T_9c404_row18_col2\" class=\"data row18 col2\" >30</td>\n",
       "      <td id=\"T_9c404_row18_col3\" class=\"data row18 col3\" >27</td>\n",
       "      <td id=\"T_9c404_row18_col4\" class=\"data row18 col4\" >22</td>\n",
       "      <td id=\"T_9c404_row18_col5\" class=\"data row18 col5\" >22</td>\n",
       "      <td id=\"T_9c404_row18_col6\" class=\"data row18 col6\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row19_col0\" class=\"data row19 col0\" >Italy</td>\n",
       "      <td id=\"T_9c404_row19_col1\" class=\"data row19 col1\" >50</td>\n",
       "      <td id=\"T_9c404_row19_col2\" class=\"data row19 col2\" >50</td>\n",
       "      <td id=\"T_9c404_row19_col3\" class=\"data row19 col3\" >48</td>\n",
       "      <td id=\"T_9c404_row19_col4\" class=\"data row19 col4\" >47</td>\n",
       "      <td id=\"T_9c404_row19_col5\" class=\"data row19 col5\" >36</td>\n",
       "      <td id=\"T_9c404_row19_col6\" class=\"data row19 col6\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row20_col0\" class=\"data row20 col0\" >Czech Republic</td>\n",
       "      <td id=\"T_9c404_row20_col1\" class=\"data row20 col1\" >31</td>\n",
       "      <td id=\"T_9c404_row20_col2\" class=\"data row20 col2\" >27</td>\n",
       "      <td id=\"T_9c404_row20_col3\" class=\"data row20 col3\" >23</td>\n",
       "      <td id=\"T_9c404_row20_col4\" class=\"data row20 col4\" >21</td>\n",
       "      <td id=\"T_9c404_row20_col5\" class=\"data row20 col5\" >20</td>\n",
       "      <td id=\"T_9c404_row20_col6\" class=\"data row20 col6\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row21_col0\" class=\"data row21 col0\" >Slovakia</td>\n",
       "      <td id=\"T_9c404_row21_col1\" class=\"data row21 col1\" >45</td>\n",
       "      <td id=\"T_9c404_row21_col2\" class=\"data row21 col2\" >45</td>\n",
       "      <td id=\"T_9c404_row21_col3\" class=\"data row21 col3\" >40</td>\n",
       "      <td id=\"T_9c404_row21_col4\" class=\"data row21 col4\" >39</td>\n",
       "      <td id=\"T_9c404_row21_col5\" class=\"data row21 col5\" >38</td>\n",
       "      <td id=\"T_9c404_row21_col6\" class=\"data row21 col6\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row22_col0\" class=\"data row22 col0\" >Syria</td>\n",
       "      <td id=\"T_9c404_row22_col1\" class=\"data row22 col1\" >156</td>\n",
       "      <td id=\"T_9c404_row22_col2\" class=\"data row22 col2\" >156</td>\n",
       "      <td id=\"T_9c404_row22_col3\" class=\"data row22 col3\" >152</td>\n",
       "      <td id=\"T_9c404_row22_col4\" class=\"data row22 col4\" >150</td>\n",
       "      <td id=\"T_9c404_row22_col5\" class=\"data row22 col5\" >149</td>\n",
       "      <td id=\"T_9c404_row22_col6\" class=\"data row22 col6\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row23_col0\" class=\"data row23 col0\" >Finland</td>\n",
       "      <td id=\"T_9c404_row23_col1\" class=\"data row23 col1\" >6</td>\n",
       "      <td id=\"T_9c404_row23_col2\" class=\"data row23 col2\" >5</td>\n",
       "      <td id=\"T_9c404_row23_col3\" class=\"data row23 col3\" >5</td>\n",
       "      <td id=\"T_9c404_row23_col4\" class=\"data row23 col4\" >1</td>\n",
       "      <td id=\"T_9c404_row23_col5\" class=\"data row23 col5\" >1</td>\n",
       "      <td id=\"T_9c404_row23_col6\" class=\"data row23 col6\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row24_col0\" class=\"data row24 col0\" >Netherlands</td>\n",
       "      <td id=\"T_9c404_row24_col1\" class=\"data row24 col1\" >7</td>\n",
       "      <td id=\"T_9c404_row24_col2\" class=\"data row24 col2\" >7</td>\n",
       "      <td id=\"T_9c404_row24_col3\" class=\"data row24 col3\" >6</td>\n",
       "      <td id=\"T_9c404_row24_col4\" class=\"data row24 col4\" >6</td>\n",
       "      <td id=\"T_9c404_row24_col5\" class=\"data row24 col5\" >5</td>\n",
       "      <td id=\"T_9c404_row24_col6\" class=\"data row24 col6\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9c404_row25_col0\" class=\"data row25 col0\" >New Zealand</td>\n",
       "      <td id=\"T_9c404_row25_col1\" class=\"data row25 col1\" >9</td>\n",
       "      <td id=\"T_9c404_row25_col2\" class=\"data row25 col2\" >8</td>\n",
       "      <td id=\"T_9c404_row25_col3\" class=\"data row25 col3\" >8</td>\n",
       "      <td id=\"T_9c404_row25_col4\" class=\"data row25 col4\" >8</td>\n",
       "      <td id=\"T_9c404_row25_col5\" class=\"data row25 col5\" >8</td>\n",
       "      <td id=\"T_9c404_row25_col6\" class=\"data row25 col6\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa2b9e02fa0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_res=pd.merge(pandas_df_15[['Country','Happiness Rank']], pandas_df_16[['Country','Happiness Rank']], on=\"Country\")\\\n",
    "        .rename(columns={'Happiness Rank_x':'Rank_2015','Happiness Rank_y':'Rank_2016'})\\\n",
    "        .query(\"Rank_2015 >= Rank_2016\")\\\n",
    "        .merge(pandas_df_17[['Country','Happiness.Rank']],on=\"Country\")\\\n",
    "        .rename(columns={'Happiness.Rank':'Rank_2017'})\\\n",
    "        .query(\"Rank_2016 >= Rank_2017\")\\\n",
    "        .merge(pandas_df_18[['Country or region','Overall rank']],left_on=\"Country\",right_on=\"Country or region\")\\\n",
    "        .rename(columns={'Overall rank':'Rank_2018'})\\\n",
    "        .query(\"Rank_2017 >= Rank_2018\")\\\n",
    "        .drop(columns='Country or region')\\\n",
    "        .merge(pandas_df_19[['Country or region','Overall rank']],left_on=\"Country\",right_on=\"Country or region\")\\\n",
    "        .rename(columns={'Overall rank':'Rank_2019'})\\\n",
    "        .query(\"Rank_2018 >= Rank_2019\")\\\n",
    "        .drop(columns='Country or region')\n",
    "        \n",
    "\n",
    "temp_res.assign(Increment_Factor=temp_res[\"Rank_2015\"] - temp_res[\"Rank_2019\"])\\\n",
    "        .sort_values('Increment_Factor',ascending=False)\\\n",
    "        .style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "|            Country|Rank_2015|Rank_2016|Rank_2017|Rank_2018|Rank_2019|Increment_Factor|\n",
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "|              Benin|      155|      153|      143|      136|      102|              53|\n",
      "|        Ivory Coast|      151|      139|      128|      107|       99|              52|\n",
      "|           Honduras|      105|      104|       91|       72|       59|              46|\n",
      "|            Hungary|      104|       91|       75|       69|       62|              42|\n",
      "|            Romania|       86|       71|       57|       52|       48|              38|\n",
      "|       Burkina Faso|      152|      145|      134|      121|      115|              37|\n",
      "|           Cameroon|      133|      114|      107|       99|       96|              37|\n",
      "|           Bulgaria|      134|      129|      105|      100|       97|              37|\n",
      "|Congo (Brazzaville)|      139|      127|      124|      114|      103|              36|\n",
      "|           Cambodia|      145|      140|      129|      120|      109|              36|\n",
      "|             Latvia|       89|       68|       54|       53|       53|              36|\n",
      "|         Tajikistan|      106|      100|       96|       88|       74|              32|\n",
      "|              Niger|      144|      142|      135|      134|      114|              30|\n",
      "| Dominican Republic|       98|       89|       86|       83|       77|              21|\n",
      "|        Philippines|       90|       82|       72|       71|       69|              21|\n",
      "|             Poland|       60|       57|       46|       42|       40|              20|\n",
      "|               Togo|      158|      155|      150|      139|      139|              19|\n",
      "|            Estonia|       73|       72|       66|       63|       55|              18|\n",
      "|              Malta|       37|       30|       27|       22|       22|              15|\n",
      "|              Italy|       50|       50|       48|       47|       36|              14|\n",
      "|     Czech Republic|       31|       27|       23|       21|       20|              11|\n",
      "|              Syria|      156|      156|      152|      150|      149|               7|\n",
      "|           Slovakia|       45|       45|       40|       39|       38|               7|\n",
      "|            Finland|        6|        5|        5|        1|        1|               5|\n",
      "|        Netherlands|        7|        7|        6|        6|        5|               2|\n",
      "|        New Zealand|        9|        8|        8|        8|        8|               1|\n",
      "+-------------------+---------+---------+---------+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_15['Country','Happiness Rank']\\\n",
    "    .withColumnRenamed(\"Happiness Rank\",\"Rank_2015\")\\\n",
    "    .join(spark_df_16['Country','Happiness Rank'].withColumnRenamed(\"Happiness Rank\",\"Rank_2016\"),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2015\") >= F.col(\"Rank_2016\"))\\\n",
    "    .join(spark_df_17['Country','`Happiness.Rank`'].withColumnRenamed(\"Happiness.Rank\",\"Rank_2017\"),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2016\") >= F.col(\"Rank_2017\"))\\\n",
    "    .join(spark_df_18.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank_2018')),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2017\") >= F.col(\"Rank_2018\"))\\\n",
    "    .join(spark_df_19.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank_2019')),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2018\") >= F.col(\"Rank_2019\"))\\\n",
    "    .withColumn('Increment_Factor', F.col(\"Rank_2015\") - F.col(\"Rank_2019\"))\\\n",
    "    .sort('Increment_Factor',ascending=False)\\\n",
    "    .show(200)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b><span style='color:#DEB078'>5.5 | </span><span style='color:#016CC9'> Find the countries which continously observed drop in rank along with year wise rank and diffence of rank from 2015 to 2019  </span></b>   \n",
    "\n",
    "* Sort the data by biggest to lowest change between 2015 to 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "|    Country|Rank_2015|Rank_2016|Rank_2017|Rank_2018|Rank_2019|Decrement_Factor|\n",
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "|  Venezuela|       23|       44|       82|      102|      108|             -85|\n",
      "|     Zambia|       85|      106|      116|      125|      138|             -53|\n",
      "|   Zimbabwe|      115|      131|      138|      144|      146|             -31|\n",
      "|      India|      117|      118|      122|      133|      140|             -23|\n",
      "|    Belarus|       59|       61|       67|       73|       81|             -22|\n",
      "|   Botswana|      128|      137|      142|      146|      148|             -20|\n",
      "|     Malawi|      131|      132|      136|      147|      150|             -19|\n",
      "|    Moldova|       52|       55|       56|       67|       71|             -19|\n",
      "|     Brazil|       16|       17|       22|       28|       32|             -16|\n",
      "| Azerbaijan|       80|       81|       85|       87|       90|             -10|\n",
      "|      Libya|       63|       67|       68|       70|       72|              -9|\n",
      "|Switzerland|        1|        2|        4|        5|        6|              -5|\n",
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"Select t1.Country ,t1.`Happiness Rank` as Rank_2015,t2.`Happiness Rank` Rank_2016,t3.`Happiness.Rank`  Rank_2017, \n",
    "            t4.`Overall rank` Rank_2018 ,t5.`Overall rank` Rank_2019,\n",
    "            (t1.`Happiness Rank`-t5.`Overall rank`) Decrement_Factor\n",
    "            from  spark_tbl_15  t1\n",
    "            inner join spark_tbl_16 t2\n",
    "            on t1.Country = t2.Country and t1.`Happiness Rank` < t2.`Happiness Rank`\n",
    "            inner join spark_tbl_17 t3\n",
    "            on t1.Country = t3.Country and t2.`Happiness Rank` < t3.`Happiness.Rank`\n",
    "            inner join spark_tbl_18 t4\n",
    "            on t1.Country = t4.`Country or region` and t3.`Happiness.Rank` < t4.`Overall rank`\n",
    "            inner join spark_tbl_19 t5\n",
    "            on t1.Country = t5.`Country or region` and t4.`Overall rank` < t5.`Overall rank`\n",
    "            order by Decrement_Factor asc\n",
    "          \n",
    "          \"\"\").show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3e3bb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_3e3bb_level0_col0\" class=\"col_heading level0 col0\" >Country</th>\n",
       "      <th id=\"T_3e3bb_level0_col1\" class=\"col_heading level0 col1\" >Rank_2015</th>\n",
       "      <th id=\"T_3e3bb_level0_col2\" class=\"col_heading level0 col2\" >Rank_2016</th>\n",
       "      <th id=\"T_3e3bb_level0_col3\" class=\"col_heading level0 col3\" >Rank_2017</th>\n",
       "      <th id=\"T_3e3bb_level0_col4\" class=\"col_heading level0 col4\" >Rank_2018</th>\n",
       "      <th id=\"T_3e3bb_level0_col5\" class=\"col_heading level0 col5\" >Rank_2019</th>\n",
       "      <th id=\"T_3e3bb_level0_col6\" class=\"col_heading level0 col6\" >Decrement_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row0_col0\" class=\"data row0 col0\" >Venezuela</td>\n",
       "      <td id=\"T_3e3bb_row0_col1\" class=\"data row0 col1\" >23</td>\n",
       "      <td id=\"T_3e3bb_row0_col2\" class=\"data row0 col2\" >44</td>\n",
       "      <td id=\"T_3e3bb_row0_col3\" class=\"data row0 col3\" >82</td>\n",
       "      <td id=\"T_3e3bb_row0_col4\" class=\"data row0 col4\" >102</td>\n",
       "      <td id=\"T_3e3bb_row0_col5\" class=\"data row0 col5\" >108</td>\n",
       "      <td id=\"T_3e3bb_row0_col6\" class=\"data row0 col6\" >-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row1_col0\" class=\"data row1 col0\" >Zambia</td>\n",
       "      <td id=\"T_3e3bb_row1_col1\" class=\"data row1 col1\" >85</td>\n",
       "      <td id=\"T_3e3bb_row1_col2\" class=\"data row1 col2\" >106</td>\n",
       "      <td id=\"T_3e3bb_row1_col3\" class=\"data row1 col3\" >116</td>\n",
       "      <td id=\"T_3e3bb_row1_col4\" class=\"data row1 col4\" >125</td>\n",
       "      <td id=\"T_3e3bb_row1_col5\" class=\"data row1 col5\" >138</td>\n",
       "      <td id=\"T_3e3bb_row1_col6\" class=\"data row1 col6\" >-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row2_col0\" class=\"data row2 col0\" >Zimbabwe</td>\n",
       "      <td id=\"T_3e3bb_row2_col1\" class=\"data row2 col1\" >115</td>\n",
       "      <td id=\"T_3e3bb_row2_col2\" class=\"data row2 col2\" >131</td>\n",
       "      <td id=\"T_3e3bb_row2_col3\" class=\"data row2 col3\" >138</td>\n",
       "      <td id=\"T_3e3bb_row2_col4\" class=\"data row2 col4\" >144</td>\n",
       "      <td id=\"T_3e3bb_row2_col5\" class=\"data row2 col5\" >146</td>\n",
       "      <td id=\"T_3e3bb_row2_col6\" class=\"data row2 col6\" >-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row3_col0\" class=\"data row3 col0\" >India</td>\n",
       "      <td id=\"T_3e3bb_row3_col1\" class=\"data row3 col1\" >117</td>\n",
       "      <td id=\"T_3e3bb_row3_col2\" class=\"data row3 col2\" >118</td>\n",
       "      <td id=\"T_3e3bb_row3_col3\" class=\"data row3 col3\" >122</td>\n",
       "      <td id=\"T_3e3bb_row3_col4\" class=\"data row3 col4\" >133</td>\n",
       "      <td id=\"T_3e3bb_row3_col5\" class=\"data row3 col5\" >140</td>\n",
       "      <td id=\"T_3e3bb_row3_col6\" class=\"data row3 col6\" >-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row4_col0\" class=\"data row4 col0\" >Belarus</td>\n",
       "      <td id=\"T_3e3bb_row4_col1\" class=\"data row4 col1\" >59</td>\n",
       "      <td id=\"T_3e3bb_row4_col2\" class=\"data row4 col2\" >61</td>\n",
       "      <td id=\"T_3e3bb_row4_col3\" class=\"data row4 col3\" >67</td>\n",
       "      <td id=\"T_3e3bb_row4_col4\" class=\"data row4 col4\" >73</td>\n",
       "      <td id=\"T_3e3bb_row4_col5\" class=\"data row4 col5\" >81</td>\n",
       "      <td id=\"T_3e3bb_row4_col6\" class=\"data row4 col6\" >-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row5_col0\" class=\"data row5 col0\" >Botswana</td>\n",
       "      <td id=\"T_3e3bb_row5_col1\" class=\"data row5 col1\" >128</td>\n",
       "      <td id=\"T_3e3bb_row5_col2\" class=\"data row5 col2\" >137</td>\n",
       "      <td id=\"T_3e3bb_row5_col3\" class=\"data row5 col3\" >142</td>\n",
       "      <td id=\"T_3e3bb_row5_col4\" class=\"data row5 col4\" >146</td>\n",
       "      <td id=\"T_3e3bb_row5_col5\" class=\"data row5 col5\" >148</td>\n",
       "      <td id=\"T_3e3bb_row5_col6\" class=\"data row5 col6\" >-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row6_col0\" class=\"data row6 col0\" >Moldova</td>\n",
       "      <td id=\"T_3e3bb_row6_col1\" class=\"data row6 col1\" >52</td>\n",
       "      <td id=\"T_3e3bb_row6_col2\" class=\"data row6 col2\" >55</td>\n",
       "      <td id=\"T_3e3bb_row6_col3\" class=\"data row6 col3\" >56</td>\n",
       "      <td id=\"T_3e3bb_row6_col4\" class=\"data row6 col4\" >67</td>\n",
       "      <td id=\"T_3e3bb_row6_col5\" class=\"data row6 col5\" >71</td>\n",
       "      <td id=\"T_3e3bb_row6_col6\" class=\"data row6 col6\" >-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row7_col0\" class=\"data row7 col0\" >Malawi</td>\n",
       "      <td id=\"T_3e3bb_row7_col1\" class=\"data row7 col1\" >131</td>\n",
       "      <td id=\"T_3e3bb_row7_col2\" class=\"data row7 col2\" >132</td>\n",
       "      <td id=\"T_3e3bb_row7_col3\" class=\"data row7 col3\" >136</td>\n",
       "      <td id=\"T_3e3bb_row7_col4\" class=\"data row7 col4\" >147</td>\n",
       "      <td id=\"T_3e3bb_row7_col5\" class=\"data row7 col5\" >150</td>\n",
       "      <td id=\"T_3e3bb_row7_col6\" class=\"data row7 col6\" >-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row8_col0\" class=\"data row8 col0\" >Brazil</td>\n",
       "      <td id=\"T_3e3bb_row8_col1\" class=\"data row8 col1\" >16</td>\n",
       "      <td id=\"T_3e3bb_row8_col2\" class=\"data row8 col2\" >17</td>\n",
       "      <td id=\"T_3e3bb_row8_col3\" class=\"data row8 col3\" >22</td>\n",
       "      <td id=\"T_3e3bb_row8_col4\" class=\"data row8 col4\" >28</td>\n",
       "      <td id=\"T_3e3bb_row8_col5\" class=\"data row8 col5\" >32</td>\n",
       "      <td id=\"T_3e3bb_row8_col6\" class=\"data row8 col6\" >-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row9_col0\" class=\"data row9 col0\" >Azerbaijan</td>\n",
       "      <td id=\"T_3e3bb_row9_col1\" class=\"data row9 col1\" >80</td>\n",
       "      <td id=\"T_3e3bb_row9_col2\" class=\"data row9 col2\" >81</td>\n",
       "      <td id=\"T_3e3bb_row9_col3\" class=\"data row9 col3\" >85</td>\n",
       "      <td id=\"T_3e3bb_row9_col4\" class=\"data row9 col4\" >87</td>\n",
       "      <td id=\"T_3e3bb_row9_col5\" class=\"data row9 col5\" >90</td>\n",
       "      <td id=\"T_3e3bb_row9_col6\" class=\"data row9 col6\" >-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row10_col0\" class=\"data row10 col0\" >Libya</td>\n",
       "      <td id=\"T_3e3bb_row10_col1\" class=\"data row10 col1\" >63</td>\n",
       "      <td id=\"T_3e3bb_row10_col2\" class=\"data row10 col2\" >67</td>\n",
       "      <td id=\"T_3e3bb_row10_col3\" class=\"data row10 col3\" >68</td>\n",
       "      <td id=\"T_3e3bb_row10_col4\" class=\"data row10 col4\" >70</td>\n",
       "      <td id=\"T_3e3bb_row10_col5\" class=\"data row10 col5\" >72</td>\n",
       "      <td id=\"T_3e3bb_row10_col6\" class=\"data row10 col6\" >-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3e3bb_row11_col0\" class=\"data row11 col0\" >Switzerland</td>\n",
       "      <td id=\"T_3e3bb_row11_col1\" class=\"data row11 col1\" >1</td>\n",
       "      <td id=\"T_3e3bb_row11_col2\" class=\"data row11 col2\" >2</td>\n",
       "      <td id=\"T_3e3bb_row11_col3\" class=\"data row11 col3\" >4</td>\n",
       "      <td id=\"T_3e3bb_row11_col4\" class=\"data row11 col4\" >5</td>\n",
       "      <td id=\"T_3e3bb_row11_col5\" class=\"data row11 col5\" >6</td>\n",
       "      <td id=\"T_3e3bb_row11_col6\" class=\"data row11 col6\" >-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa2c89e3850>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp_res=pd.merge(pandas_df_15[['Country','Happiness Rank']], pandas_df_16[['Country','Happiness Rank']], on=\"Country\")\\\n",
    "        .rename(columns={'Happiness Rank_x':'Rank_2015','Happiness Rank_y':'Rank_2016'})\\\n",
    "        .query(\"Rank_2015 < Rank_2016\")\\\n",
    "        .merge(pandas_df_17[['Country','Happiness.Rank']],on=\"Country\")\\\n",
    "        .rename(columns={'Happiness.Rank':'Rank_2017'})\\\n",
    "        .query(\"Rank_2016 < Rank_2017\")\\\n",
    "        .merge(pandas_df_18[['Country or region','Overall rank']],left_on=\"Country\",right_on=\"Country or region\")\\\n",
    "        .rename(columns={'Overall rank':'Rank_2018'})\\\n",
    "        .query(\"Rank_2017 < Rank_2018\")\\\n",
    "        .drop(columns='Country or region')\\\n",
    "        .merge(pandas_df_19[['Country or region','Overall rank']],left_on=\"Country\",right_on=\"Country or region\")\\\n",
    "        .rename(columns={'Overall rank':'Rank_2019'})\\\n",
    "        .query(\"Rank_2018 < Rank_2019\")\\\n",
    "        .drop(columns='Country or region')\n",
    "        \n",
    "\n",
    "temp_res.assign(Decrement_Factor=temp_res[\"Rank_2015\"] - temp_res[\"Rank_2019\"])\\\n",
    "        .sort_values('Decrement_Factor')\\\n",
    "        .style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "|    Country|Rank_2015|Rank_2016|Rank_2017|Rank_2018|Rank_2019|Decrement_Factor|\n",
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "|  Venezuela|       23|       44|       82|      102|      108|             -85|\n",
      "|     Zambia|       85|      106|      116|      125|      138|             -53|\n",
      "|   Zimbabwe|      115|      131|      138|      144|      146|             -31|\n",
      "|      India|      117|      118|      122|      133|      140|             -23|\n",
      "|    Belarus|       59|       61|       67|       73|       81|             -22|\n",
      "|   Botswana|      128|      137|      142|      146|      148|             -20|\n",
      "|     Malawi|      131|      132|      136|      147|      150|             -19|\n",
      "|    Moldova|       52|       55|       56|       67|       71|             -19|\n",
      "|     Brazil|       16|       17|       22|       28|       32|             -16|\n",
      "| Azerbaijan|       80|       81|       85|       87|       90|             -10|\n",
      "|      Libya|       63|       67|       68|       70|       72|              -9|\n",
      "|Switzerland|        1|        2|        4|        5|        6|              -5|\n",
      "+-----------+---------+---------+---------+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_15['Country','Happiness Rank']\\\n",
    "    .withColumnRenamed(\"Happiness Rank\",\"Rank_2015\")\\\n",
    "    .join(spark_df_16['Country','Happiness Rank'].withColumnRenamed(\"Happiness Rank\",\"Rank_2016\"),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2015\") < F.col(\"Rank_2016\"))\\\n",
    "    .join(spark_df_17['Country','`Happiness.Rank`'].withColumnRenamed(\"Happiness.Rank\",\"Rank_2017\"),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2016\") < F.col(\"Rank_2017\"))\\\n",
    "    .join(spark_df_18.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank_2018')),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2017\") < F.col(\"Rank_2018\"))\\\n",
    "    .join(spark_df_19.select(F.col('Country or region').alias('Country'),F.col('`Overall rank`').alias('Rank_2019')),on='Country')\\\n",
    "    .filter(F.col(\"Rank_2018\") < F.col(\"Rank_2019\"))\\\n",
    "    .withColumn('Decrement_Factor', F.col(\"Rank_2015\") - F.col(\"Rank_2019\"))\\\n",
    "    .sort('Decrement_Factor')\\\n",
    "    .show(200)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
